#!/bin/bash 

. bin/functions.sh

declare -a ARGS
AWS_ARGS=""

while [ -n "$*" ] ; do
    case $1 in
	--profile) AWS_ARGS="--profile $2"; shift;;
	*) ARGS+=($1);;
    esac
    shift
done

function aws() {
    command aws $AWS_ARGS "$@"
}

set -- "${ARGS[@]}"

# Set to .params if not set in environment already
: ${PARAMS_DIR=./params}

echo "Using params from: " $PARAMS_DIR


GLOBAL_PARAMS_FILE=${PARAMS_DIR}/global.params
PROVISION_PARAMS_FILE=${PARAMS_DIR}/provision.params

# Determine how script was invoked
INVOCATION_NAME=$( basename $0 )

# Determine name of CF template to use ...
NAME=${1}
echo "Attempting to use template: '${NAME}'"

#
# Test invocation and arguments
#
if [ "$#" -lt 1 ]; then
    echo "Usage: ${INVOCATION_NAME} template_name [stack_name]"
    exit 1
fi


# CFN_FILE=$( find cfn -name ${NAME}.cfn.json | head -1 )
# # if we can compress the CF json file
# if [ check_for_jq ]; then
#     tmpfile=$( maketemp )
#     cat ${CFN_FILE} | jq -c > ${tmpfile}
#     CFN_FILE=${tmpfile}
# fi
# CFN_URL="file://${CFN_FILE}"

# if [ ! -r "${CFN_FILE}" ]; then
#   echo "Cannot find suitable CF file: ${NAME}.cnf.json"
#   echo "Please check for file and name provided."
#   exit 0;
# fi

CFN_URL=$( get_cfn_url ${NAME} )

# This was confusing provision.py and finding random versions of pega.params files 
# PARAMS_FILE=$( find ${PARAMS_DIR} -name ${NAME}.params | head -1 )

PARAMS_FILE="${PARAMS_DIR}/${NAME}.params"
PARAMS_URL=$( get_params_url ${NAME} )

echo $PARAMS_FILE
echo $PARAMS_URL


# if ! [  -r "${PARAMS_FILE}" ]; then
#     echo "Cannot find suitable params file: ${NAME}.params"
#     echo "Please check file and name provided."
#     exit 0;
# fi

# Static arguments to the aws CLI
#AWS_PROFILE="--profile corporate"
ROLLBACK=--disable-rollback
CAPABILITIES="--capabilities CAPABILITY_IAM"

# stack name is by default CF name, with optional 2nd argument
#  to set to something different.

STACK_NAME=${2:-$NAME}

push_code_to_S3 () {
    bucket=$1

    aws --region us-east-2  s3 sync --delete ./cfn s3://${bucket}/cfn \
                --exclude "**/.DS_Store" \
                --exclude ".git/**" \
                --exclude "*.graffle" \
                --exclude "params/*.params"\
                --exclude "CMDB"
    echo "Done with sync to S3"   
 }

#
# Read in params as bash variables
#
load_params() {

    local tmpfile=$( maketemp )
    local params_file=$1

    [ -r "${GLOBAL_PARAMS_FILE}" ] && cat ${GLOBAL_PARAMS_FILE} | parse_yaml >> $tmpfile
    [ -r "${params_file}"        ] && cat "${params_file}"      | parse_yaml >> $tmpfile
    [ -r "${PROVISION_PARAMS_FILE}" ] && cat "${PROVISION_PARAMS_FILE}" | parse_yaml >> $tmpfile

    while read -r line
    do
        eval "export $line"
    done < "$tmpfile"

    rm -f $tmpfile
}

#
# write to stdout suitable CF params JSON
#  
#
generate_params_json() {

    cf_file=$1
    params_file=$2

    load_params ${params_file}

    parameter_keys=$( find_cf_params $cf_file )
    echo "["
    for k in ${parameter_keys}; do
        val=$( eval echo \$$k )
        if ! [ -z "${val}" ]; then
            echo "  { \"ParameterKey\": \"$k\",  \"ParameterValue\": \"${val}\" },"
        fi
    done

    echo "  { \"ParameterKey\": \"DeployBucketPrefix\", \"ParameterValue\": \"undefined\" }"

    echo "]"

}

#
# create 
#
generate_params_file() {

    cf_file=$( echo $1 | sed 's/file:\/\///' )
    params_file=$2
    local tmpfile=$( maketemp )
    generate_params_json "${cf_file}" "${params_file}" >> "${tmpfile}"
    echo $tmpfile
}

query_status() {
    local stack_name=$1
    local result=$( aws cloudformation \
                     ${AWS_PROFILE} describe-stacks \
                     --stack-name ${stack_name} \
                     --query 'Stacks[0].StackStatus' )
    echo ${result}
}

do_create () { 
    PARAMS_JSON_FILE=$( generate_params_file ${CFN_URL} ${PARAMS_FILE} )
    
    cmd="aws cloudformation \
        ${AWS_PROFILE} \
        create-stack \
        --stack-name    ${STACK_NAME} \
        --template-body ${CFN_URL} \
        --parameters    file://${PARAMS_JSON_FILE} \
        --tags Key=Owner,Value="$(whoami)" \
        ${CAPABILITIES} ${ROLLBACK}"
    echo ${cmd}
    ${cmd}

    echo ${PARAMS_JSON_FILE}
    cat ${PARAMS_JSON_FILE}
} 

do_update () { 

    PARAMS_JSON_FILE=$( generate_params_file ${CFN_URL} ${PARAMS_FILE} )
    cmd="aws cloudformation \
        ${AWS_PROFILE} \
        update-stack   \
        --stack-name    ${STACK_NAME} \
        --template-body ${CFN_URL} \
        --parameters    file://${PARAMS_JSON_FILE}  \
        ${CAPABILITIES}"
    echo ${cmd}
    ${cmd}
    rm -f ${PARAMS_JSON_FILE}

}

do_delete () { 
    aws cloudformation ${AWS_PROFILE} delete-stack --stack-name ${STACK_NAME} 
}

do_monitor () { 

    result=$( query_status ${STACK_NAME} )
    echo Status of stack \"${STACK_NAME}\" : ${result}
    while [ "CREATE_IN_PROGRESS" = "$result" ]; do
        sleep 60
        result=$( query_status ${STACK_NAME} )
        echo Status of stack \"${STACK_NAME}\" : $result
    done

    if [ "CREATE_FAILED" = "$result" ]; then
        aws cloudformation ${AWS_PROFILE} describe-stacks \
           --stack-name ${STACK_NAME} 
        exit 1
    fi
    if [ "CREATE_COMPLETE" = "$result" -o "DELETE_IN_PROGRESS" = "$result" ]; then
        exit 0
    fi

}

#
# Establish SSH tunnels in template outputs
#
do_setup_tunnels () { 

    local stack_name=${STACK_NAME}
    local result=$( get_stack_outputs ${stack_name} )
    for r in ${result}; do 
        ssh_cmd=$( echo $r | grep "^ssh" )
        echo $ssh_cmd
    done 

}

do_validate () { 
    aws cloudformation ${AWS_PROFILE} validate-template  --template-body ${CFN_URL} 
}

do_parameters() { 
    local CFN_FILE=$( echo ${CFN_URL} | sed 's/file:\/\//' )
    cat "${CFN_FILE}" | report_on_cf_params
}

# -----------------------------
#
#  MAIN: Let's do this thing!
#
#-------------------------------


#
# push syntax
#
if [ "${INVOCATION_NAME}" = "push" ]; then 
    load_params ${PARAMS_FILE}
  #  check_git_working_directory
    arrB=(${Buckets//,/ })
    push_code_to_S3 ${arrB[0]}
    echo 
    echo "Pushed codebase to s3://${arrB[0]}/"
    echo    
    exit 0
fi

#
# create syntax
#
if [ "${INVOCATION_NAME}" = "create" ]; then 
    load_params ${PARAMS_FILE}
#    check_git_working_directory
    arrB=(${Buckets//,/ })
    push_code_to_S3 ${arrB[0]}
    do_create
    exit 0
fi

#
# Update syntax
#
if [ "${INVOCATION_NAME}" = "update" ]; then 
    load_params ${PARAMS_FILE}
   # check_git_working_directory
    arrB=(${Buckets//,/ })
    push_code_to_S3 ${arrB[0]}
    do_update
    exit 0
fi

#
# Delete syntax
#
if [ "${INVOCATION_NAME}" = "delete" ]; then 
    do_delete
    exit 0
fi

#
# Monitor stack
#
if [ "${INVOCATION_NAME}" = "monitor" ]; then 
    do_monitor
    exit 0
fi

#
# Setup SSH tunnels for complete master stack (WIP)
#
if [ "${INVOCATION_NAME}" = "setup-tunnels" ]; then 
    do_setup_tunnels
    exit 0
fi

#
# Validate the template syntax
#
if [ "${INVOCATION_NAME}" = "validate" ]; then 
    do_validate
    exit 0
fi

#
# Report out the parameters in the template
#
if [ "${INVOCATION_NAME}" = "parameters" ]; then 
    do_parameters
    exit 0
fi

